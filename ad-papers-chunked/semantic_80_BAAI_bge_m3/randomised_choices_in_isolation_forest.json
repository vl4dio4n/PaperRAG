[{"id_": "9fa83a2f-f3f2-4425-97a5-e89f221c43bf", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ec2cec38-259f-46eb-a96e-d57a0bece62a", "node_type": "1", "metadata": {}, "hash": "251415d28749d814a8828fbac66d9f0616b95e515ec71472d77267f89880e492", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "arXiv:2110.13402v3 [stat.ML] 6 Dec 2021\n\n# Revisiting randomized choices in isolation forests\n\nDavid Cortes\n\nDecember 7, 2021\n\n## Abstract\n\nIsolation forest or \"iForest\" is an intuitive and widely used algorithm for anomaly detection that follows a simple yet effective idea: in a given data distribution, if a threshold (split point) is selected uniformly at random within the range of some variable and data points are divided according to whether they are greater or smaller than this threshold, outlier points are more likely to end up alone or in the smaller partition. The original procedure suggested the choice of variable to split and split point within a variable to be done uniformly at random at each step, but this paper shows that \"clustered\" diverse outliers - oftentimes a more interesting class of outliers than others can be more easily identified by applying a non-uniformly-random choice of variables and/or thresholds. Different split guiding criteria are compared and some are found to result in significantly better outlier discrimination for certain classes of outliers.\n\n## 1 Introduction\n\nThe isolation forest (a.k.a. IFOREST, [14]) algorithm for anomaly detection tries to exploit the idea that outliers, by definition, are \"few and different\u201d from normal data points. The premise behind the algorithm is very intuitive: in a given distribution of data points X \u2208 R\u1d50\u02e3\u207f, if picking a variable (column) at random within the data, if one selects a value uniformly at random within the range of the data distribution for that variable and then groups observations (rows) according to whether they are greater or smaller than this threshold across the chosen variable, then outliers (anomalies) have a larger chance of ending up alone or in a smaller group when compared to normal observations.\n\nThe algorithm exploits this idea by performing recursive partitions of the data - that is, a given set or subset of points is first split according to this random choice, then at each branch or group that this division produces, the procedure is repeated again but this time considering only the points that reached this subset, and it continues doing so until each point becomes isolated (is the only point present in a given division) or until some other termination criteria is met. Under this scheme, outlier points will in expectation take fewer steps/divisions/branchings to become isolated, and thus the expected isolation depth can be used as an anomaly score for each point (the shorter, the more anomalous).\n\nFor better results, this procedure is repeated many times (suggestion in [14] was 100 times), with each different run (from here on, a \"decision tree\" or simply \"tree\") taking only a small sub-sample of the data (suggestion in [14] was to sub-sample 256 points without replacement for each tree), with the observed isolation depth for each observation averaged across trees - the set of which form a \"forest\" - and compared against the expected isolation depth if all the data were distributed uniformly at random across all dimensions.\n\nFor a more computationally efficient implementation, the procedure may be stopped before reaching isolation of every point at a given tree, since outliers can only be considered to be so if their isolation depth is below average, and thus a remainder can be extrapolated for points that reach a non-isolated node with depth greater or equal than the expected average for uniformly-random data. The expected isolation depth (and thus the extrapolated remainder) can be approximated efficiently through a closed-form formula (see [1]), resulting in a very fast procedure compared to e.g. distance-based algorithms such as LOF (\"local outlier factor\", [4]).\n\nThe isolation forest algorithm as-is has enjoyed wide success and widespread usage, achieving good results in a variety of benchmarks encompassing different types of outliers (see e.g. [5]) and usually outperforming other model classes, although some issues have been identified with the logic behind the algorithm (e.g. ", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4052, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ec2cec38-259f-46eb-a96e-d57a0bece62a", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9fa83a2f-f3f2-4425-97a5-e89f221c43bf", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "85720a5ec2ef2649b2bf6fcea2b5e0a338fba9cdddfd2075aa4083077385cd1b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c7c1629-95f1-48f4-ac4c-e621d45a2eef", "node_type": "1", "metadata": {}, "hash": "be7417a4f9e8bfe04b3b7367cd032e61344835d7d48dca710250bb16bea49be2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "in [2]). ", "mimetype": "text/plain", "start_char_idx": 4052, "end_char_idx": 4061, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "8c7c1629-95f1-48f4-ac4c-e621d45a2eef", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ec2cec38-259f-46eb-a96e-d57a0bece62a", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "77de40bd90b83b2631f468da2d02195c56de9d7ef0f982eec70911e6d4d17a3c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f03a95bd-8fd3-4ca0-a032-3c9633594b93", "node_type": "1", "metadata": {}, "hash": "ac383f5fb562fbc126251e2e4de4d6fa78a3184e6edc3985a69b2e6df276c0d8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Many subsequent works have built upon the idea to create better variations of the procedure, some of which will be analyzed in the next sections.\n\nWhile overall useful as a general outlier detector and perhaps one of the best all-around methods as measured by aggregated metrics across benchmarks, a deeper look at performance comparisons in the literature would reveal that IFOREST and modifications thereof typically outperform other classes of methods in certain types of datasets, but not in all of them. This work tries to characterize these cases and proposes a different guiding heuristic for split selection in IFOREST, which is compared against similar ideas and found to outperform them in datasets in which isolation-based methods dominate others, at the expense of hindered performance in datasets in which non-tree-based methods outperform IFOREST.\n\n## 2 Related work\n\nThere are many potential ways in which the isolation forest procedure can be improved upon while following the same core concept behind it. For example, [12] highlights biases that are introduced by the way that data splits are created and shows some simple ways in which the procedure can fail to produce adequate results, proposing a simple fix (the \"extended isolation forest\" algorithm or EIF) which, instead of producing splits by one variable at a time (or \"axis-parallel splits\u201d), produces split thresholds with respect to randomly-generated hyperplanes, which encompass only a couple of variables at a time.\n\nThe same extension is taken a step further in the \"split criterion isolation forest\" or SCIFOREST from [15], proposing not only doing the splits by random hyperplanes, but also determining the split threshold by a deterministic criterion that aims at making each tree branch (groups that are obtained after dividing points according to the threshold) more homogeneous, and reporting increased performance metrics in typical anomaly detection datasets from these changes.\n\nThe \"robust random cut forest\" or RRCF from [11] proposed choosing the variable to split with a probability proportional to the range that it spans instead of choosing it uniformly at random, following the idea that variables with a wider ranger are more important in a multivariate distribution and more likely to differentiate outliers.\n\nOther models such as the \"density estimation trees\" or DET from [17] also propose more elaborate criteria for choosing the variable and the split point, in the case of [17] considering the distribution of all variables rather than just a subset of them as in [15], and choosing both the variable to split and the split point within the variable according to a deterministic criterion that aims at grouping together more points where the multivariate density of the data is higher, with density viewed as the amount of points per volume unit in the space spanned by the features. The \"generalized isolation forest\" (GIF) from [5] and the \"one-class random forest\" (OCRF) from [9] also proposed similar ideas, but with slightly different splitting criteria.\n\n## 3 Different types of outliers\n\nSo far, outliers or anomalies have only been characterized here as being \"few and different\" - for example, in typical datasets for outlier detection, outliers are sampled from a minority group which differs in some fundamental aspect from the majority, such as cross-sectional measurements of soil samples in which outliers are measurements taken from a different type of soil than the rest. This nevertheless does not provide the full picture, as \"outliers\u201d or \"anomalies\u201d in a dataset can be generated by different events or processes, such as incorrect data entry or attempted fraudulent purchases.\n\nA lot of literature has been written about \"extreme value\" identification in univariate distributions, which is one type of anomaly in which the value for some particular variable in an observation is very different from the rest, and can be caused e.g. by incorrect data entry that types an additional digit. More interesting classes of anomalies however typically involve relationships between many variables, with outliers not necessarily having extreme values in any particular variable, but presenting relationships between them which do not match with the rest. Most of the \"anomaly detection\" or \"one-class classification\" literature as well as public datasets focus on these cases.\n\nA distinction is made in [15] between \"scattered\" and \"clustered\" outliers, with the \"clustered\" outliers being considered as more \"interesting\", as they are classes of outliers which typically originate through some repeated process (such as fraudulent activity) as opposed to \"scattered\" outliers which originate from unrelated events. These \"clustered\u201d outliers are deemed harder to identify due to aspects such as \"masking\", which [15] tries to address in its proposed method.\n\nMost of the literature nevertheless makes no distinctions between classes of outliers. Oftentimes, a new method is introduced, and its utility demonstrated by identifying a pattern of anomality in randomly-generated data and aggregating performance metrics across different datasets, evaluating the method as a general anomaly detector. Such a presentation however provides an incomplete depiction, as different methods make a trade-off in being better at identifying certain classes of outliers at the expense of being worse at identifying others as will be shown in the following sections, but such trade-off is rarely discussed.\n\nFor example, methods based on density or likelihood such as DET will determine outlierness according to how uncommon a combination of values would be, which in a multi-modal distribution would give a more anomalous value to observations that cluster near one of the non-majority modes compared to those that cluster near the largest mode, while methods based on local outlierness or neighborhoods such as iNNE from [2] would not deem observations near minority modes any less anomalous than those near majority modes. For outliers such as those in the \"Satellite\" dataset\u00b9 for example, the latter might\n\n\u00b9http://odds.cs.stonybrook.edu/satellite-dataset/\n\nbe a disadvantage, while for outliers in the \"ForestCover\" dataset\u00b2 such a property would be desirable.\n\nThis work shows that there is no \"silver bullet\" and suggests that different methods should be employed for different outlier types or desired anomalous patterns to catch.\n\nWhile many previous works have tried to make a distinction between \"global\" and \"local\" outliers, there are other perhaps more important aspects which could be used to categorize them. In the public datasets that are typically used to compare algorithms (from e.g. ", "mimetype": "text/plain", "start_char_idx": 4061, "end_char_idx": 10771, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f03a95bd-8fd3-4ca0-a032-3c9633594b93", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c7c1629-95f1-48f4-ac4c-e621d45a2eef", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "c1c685a10f5ad3f71ba8820d2045651d0057d4d5c016e24ea60951c7375dc520", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "70d6d8f4-baed-436d-be3e-07b8ee4a394a", "node_type": "1", "metadata": {}, "hash": "b3789cf45eef1de4f6d36546e910395152f8bac7df72561f60abda766a32e101", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[18] or [6], which have been used in e.g. ", "mimetype": "text/plain", "start_char_idx": 10771, "end_char_idx": 10813, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "70d6d8f4-baed-436d-be3e-07b8ee4a394a", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f03a95bd-8fd3-4ca0-a032-3c9633594b93", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "0245953b26cfd4612403dd43bd134ab2363f602d7d083ae1570137b13c9f378f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4c445684-5455-4006-bef2-a54867eb02fc", "node_type": "1", "metadata": {}, "hash": "9ec8b2ab6686b4b2b8301f88ad2c3e679fee0c083b7e8ad7c78b4e3b2253ae3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[14], [15], [5], [10], and many others), one could also make a distinction according to the data generation process - for example:\n\n1. Imbalanced binary classification, in which anomalies are all from a different class to which less than 1% of the observations belong. These are in general the easiest datasets to simulate. ", "mimetype": "text/plain", "start_char_idx": 10813, "end_char_idx": 11137, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4c445684-5455-4006-bef2-a54867eb02fc", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "70d6d8f4-baed-436d-be3e-07b8ee4a394a", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "0b6b4bc4a4322cd5abcd1add7f3931112a5eac4a36e3780f304abdaf709c2b4e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6adbe44f-27f7-42a8-b2f7-e809e88a1fb1", "node_type": "1", "metadata": {}, "hash": "2326e342380e4a9e056395827a05c94f00215daa54181eaf935b41090f52ca22", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Datasets such as as \"Pima\", \"Forest Cover\" and \"Mnist\" belong to this group.\n", "mimetype": "text/plain", "start_char_idx": 11137, "end_char_idx": 11214, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6adbe44f-27f7-42a8-b2f7-e809e88a1fb1", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4c445684-5455-4006-bef2-a54867eb02fc", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "9d33192cc804506cc778b0b8fba7402e05408c81eac51e8d114cc115ae527e6b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b8152f68-0ffc-45fd-866b-405cf0550c5c", "node_type": "1", "metadata": {}, "hash": "029e0a1f381cb28725801928ae3a96e04fa8c07b5177c286064460c72548581b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2. Rare and \"scattered\" outliers, typically from multi-class classification, in which very few points belonging to different minority classes are added to a majority class or classes. Datasets such as \"ALOI\" belong to this group.\n3. Multi-label classification in which minority classes are grouped together as outliers, typically representing a much larger percentage of the total than in the imbalanced classification scenario, and the non-anomalous cases sometimes being a mixture of different majority classes. Datasets such as \"Satellite\", \"Arrhythmia\" and \"Annthy-roid\" belong to this group.\n\nThis is not by any means a comprehensive categorization (one could also make a distinction according to e.g. variable distributions), and not all datasets or outlier types belong to any of these groups - for instance, the \"Pendigits\" dataset is a multi-label classification scenario in which outliers are a single down-sampled class while inliers are the non-downsampled classes. Other datasets such as \"SpamBase\u201d could be considered a mixture of minority-classes and scattered outliers. Practical applications with non-artificial outliers are likely to encompass a mixture of different such scenarios, with areas like fraud detection being likely more similar to the \"SpamBase\" case than to the \"ForestCover\u201d, for example.\n\nWhen looked from this perspective, it becomes logical to suspect that e.g. ", "mimetype": "text/plain", "start_char_idx": 11214, "end_char_idx": 12612, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b8152f68-0ffc-45fd-866b-405cf0550c5c", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6adbe44f-27f7-42a8-b2f7-e809e88a1fb1", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "c628aa6791e366c6aee03525bc3b3be59b123749826819b9d455eec16649a15c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "00de3127-8387-46d2-b24e-4d3b9a721955", "node_type": "1", "metadata": {}, "hash": "a4d8e997e15e24c6c4e175557153035aca69ea797a3d6d567773bffd6002c17b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "highly-local methods might be very suitable for the second group, but not for the third group, while not-so-granular methods such as the linear models from [19] could be very suitable for the first group. ", "mimetype": "text/plain", "start_char_idx": 12612, "end_char_idx": 12817, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "00de3127-8387-46d2-b24e-4d3b9a721955", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b8152f68-0ffc-45fd-866b-405cf0550c5c", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "9291cdc8e04cdee1795a491b432c333d9686f9bbfcb8e1cedbb382063f31bf3b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7ace852-48b5-402e-9f04-be4c6df2b226", "node_type": "1", "metadata": {}, "hash": "af78d3e4ebac32aeb2bc3d9cc6a99d5f82ca2356a1af70d25fb8afa43c8a5b77", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The first and third group could both be considered to be \"clustered\" outliers, and both are likely to be the cases of utmost interest in different types of applications, but methods that do well for one might not do so well for the other.\n\nIf taking IFOREST as a base, a quick experiment would show that different ways of choosing the split threshold or the variable to split would present visible trade-offs across datasets among others, one could think of using kurtosis as a way to choose variables in order to catch extreme-valued outliers (in this experiment, by picking columns with a probability proportional to their kurtosis), or use an information gain criterion to determine the split threshold in the chosen variable similarly to [7] (more on this method to follow in the next sections):\n\n\u00b2http://odds.cs.stonybrook.edu/forestcovercovertype-dataset/\n\n| Table 1: iForest with different feature and split selection strategies | | | |\n| :--- | :---: | :---: | :---: |\n| | **Area under the ROC curve** | | |\n| **Guiding heuristic** | **Satellite** | **Annthyroid** | **Pendigits** |\n| Uniformly random | 0.718 | 0.827 | 0.957 |\n| Kurtosis | 0.711 | 0.979 | 0.945 |\n| Pooled gain | 0.857 | 0.829 | 0.948 |\n\nBoth of which would lead to improved outlier detection in one dataset but not in the other two, thus making it impossible to say that one configuration is better than the others as a general outlier detector, but suggesting that a single universal outlier detector might not be the best approach either.\n\nThe overall hardest classes of outliers are perhaps those in which variable distributions are multi-modal and outliers are \"clustered\" around many different minority modes of different combinations of variables (such as the \"Satellite\u201ddataset). These are coincidentally the cases in which IFOREST tends to outperform other families of methods, and will be the focus of interest here, at the expense of other classes of outliers.\n\n## 4 Non-uniformly-random trees\n\nDET and SCIFOREST both suggest that carefully-chosen split points could result in improved outlier detectors compared to uniformly-random splits, but the metrics they aim at maximizing are quite different and lead to very dissimilar types of data partitions and tree structures.\n\nThe SCIFOREST model, looked from a slightly different perspective, will at each step first generate a random linear combination of a few variables (suggestion was two variables at a time), and then look for the split threshold that minimizes the average of the standard deviation of this linear combination of variables in each side of the split. For a better-quality partition, [15] suggests trying many different linear combinations (suggestion is 10) at each step, and standardizing these numbers to make them comparable, proposing a \"gain\" criterion in a similar spirit as in supervised decision tree algorithms:\n\ngain_avg = (\u03c3_all - (\u03c3_left + \u03c3_right)/2) / \u03c3_all\n\nWhere \u03c3_left and \u03c3_right are the standard deviations observed in the distribution of the randomly-generated linear combination among the points that go to each side of the comparison threshold (\"less than\" and \"greater than\") set upon this same linear combination, and \u03c3_all is the standard deviation among these points before partitioning them.\n\nThis split criterion will tend to favor partitions in which only one or a few points are put into a single branch while the majority go to the other, leading to quick isolation of extreme-valued points but perhaps generating insufficient discrimination among non-extreme values. As many points quickly start becoming isolated in earlier splits, it takes relatively fewer splits to reach the same termination criterion used by \"iForest\", resulting in smaller trees (containing fewer nodes) and thus in principle a computationally-efficient procedure if the termination criteria remains the same. It should be noted however that the expected isolation depth for uniformly-random data in this case would not be the same as for the simpler IFOREST, but would rather be a usually larger number, given by:\n\nE[d(m)] = (\u03a3_{i=1}^{m} i) - 1 / m\n\nWhere m is the number of uniformly-random points. This comes from the fact that the optimal split for uniformly-random data corresponds to leaving a single observation in one branch and the rest in the other.\n\n***\n**Figure 1: Expected isolation depth for 4 uniform points under averaged gain**\n\n*Description: A diagram shows a simple binary tree. A root node labeled '1' splits into two child nodes. ", "mimetype": "text/plain", "start_char_idx": 12817, "end_char_idx": 17331, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b7ace852-48b5-402e-9f04-be4c6df2b226", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "00de3127-8387-46d2-b24e-4d3b9a721955", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "e1337178adfc4dee0690db7af1a3ddd4cc33a3c30c6d48aeac196564b81c145f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4c25f647-cda6-471d-8317-80ed71b8c5bc", "node_type": "1", "metadata": {}, "hash": "412085f8c3bbd02ae49b297325fcbcf9c4545810fa8b21c31f0bed344bb3d3c4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The left child, labeled '2', splits into two leaf nodes. ", "mimetype": "text/plain", "start_char_idx": 17331, "end_char_idx": 17388, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4c25f647-cda6-471d-8317-80ed71b8c5bc", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7ace852-48b5-402e-9f04-be4c6df2b226", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "4a696da8cfed4f184c6df8417b833a7b8f1405c000ed6098dda7bb06265e5251", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6a9a64fb-9ca8-4f37-9f54-efdf318b3c16", "node_type": "1", "metadata": {}, "hash": "e0f3ab8f70e9a76ae6c06c26cbcc093f081fa1602b6ee0987b72efcf60dd1f66", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The right child is a leaf node. The calculation `E[d(4)] = (1+2+3+3)/4 = 2.25` is displayed, indicating the average depth of the 4 leaf nodes.*\n***\n\nA small experiment with the \"Satellite\" dataset reveals that the expected isolation depth from IFOREST might indeed not be as appropriate for SCIFOREST:\n\n***\n**Figure: Real vs extrapolated isolation depth (Satellite dataset)**\n\n*Description: Two scatter plots are shown side-by-side.\nThe left plot, titled \"iForest\", shows \"Full isolation depth\" vs. ", "mimetype": "text/plain", "start_char_idx": 17388, "end_char_idx": 17887, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6a9a64fb-9ca8-4f37-9f54-efdf318b3c16", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4c25f647-cda6-471d-8317-80ed71b8c5bc", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "cb0dc4cc9841ec20dc56c50e2e49826e07d4663267abdeba032135a64b52ec9a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8016b653-a01e-4392-8316-331ff6cb5a61", "node_type": "1", "metadata": {}, "hash": "2eadb7ca422fa08e5a2f7091439ef1ea72743556aea47d39c90510a710a6c136", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"Extrapolated isolation depth\". The points form a tight, linear cluster, with a correlation (rho) of 0.958.\nThe right plot, titled \"SCiForest\", shows the same axes. The points are much more scattered, forming a wider, less linear cloud, with a correlation (rho) of 0.772.*\n***\n\nNevertheless, [15] kept the same threshold and remainder extrapolation as in the original IFOREST in their design.\n\nWhen data distributions are multi-modal and these modes very separable, this averaged gain criterion can tend to result in quick separation of groups, but at the expense of so-called \"ghost regions\u201d (see [12]), the moreso if a remaining depth is extrapolated instead of running the procedure until full isolation:\n\n***\n**Figure 2: Anomaly scores from SCiForest in randomly-generated bimodal data, with no sub-sampling to make the effects more visible. The redder, the higher the anomaly score.", "mimetype": "text/plain", "start_char_idx": 17887, "end_char_idx": 18774, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "8016b653-a01e-4392-8316-331ff6cb5a61", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6a9a64fb-9ca8-4f37-9f54-efdf318b3c16", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "1e34886079f84b794a52131e66c063edbffc1ef99057c479a7edbb2bb04b17ce", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ff876342-a2fa-40ab-935e-e9977aa549cb", "node_type": "1", "metadata": {}, "hash": "a3495c540eb4a31d698851d1d9f121a6cd37cd080cf7ace4a5867dc347b3c09a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "**\n\n*Description: Two heatmaps are shown side-by-side.\nThe left heatmap is titled \"SCiForest anomaly scores, Extrapolated depths\". It shows two distinct red (high anomaly score) circular regions corresponding to the modes of the bimodal data. There is also a red region between the two modes, the \"ghost region\".\nThe right heatmap is titled \"Full depths\". ", "mimetype": "text/plain", "start_char_idx": 18774, "end_char_idx": 19130, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ff876342-a2fa-40ab-935e-e9977aa549cb", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8016b653-a01e-4392-8316-331ff6cb5a61", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "ee14cb4cd49794e6a4a402204e02f3cb244dcabac20a2a964eb5b1289f62f9cd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "696a7fa4-0a94-4fdf-b821-9e2ec8cc3147", "node_type": "1", "metadata": {}, "hash": "c7d136e085c45ca9bbf539f2c00fee7bb49aafba75e325455daf8ea7f1d0add3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It is very similar to the left one, showing two red circular regions and a red ghost region between them.*\n***\n\nPerhaps counterintuitively, the splits generated following this criterion seem to be less sensitive to the presence of local outliers in the training data compared to uniformly-random choices:\n\n***\n**Figure 3: Influence of an outlier in the splits generated through different guiding criteria**\n\n*Description: A 2x3 grid of heatmaps is shown.\nThe top row is titled \"Uniformly-random splits\". ", "mimetype": "text/plain", "start_char_idx": 19130, "end_char_idx": 19634, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "696a7fa4-0a94-4fdf-b821-9e2ec8cc3147", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff876342-a2fa-40ab-935e-e9977aa549cb", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "9f146b8a0cca2b11f958afa422d22e93c8cc62fb3d88dc49c79a9f984b7a7fe2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "81559909-fc40-4a1a-a287-797c32fdabd3", "node_type": "1", "metadata": {}, "hash": "6e1fee9b4407883c1be3594746602668edcd82996b3a60107f0873ba81937fdc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The three heatmaps show anomaly scores for \"No outlier\", \"Outlier at top-left\", and \"Outlier at bottom-right\". The heatmaps clearly show the two modes of the bimodal data. When an outlier is added, its location becomes a small, high-anomaly (red) spot, influencing the scores around it.\nThe bottom row is titled \"Averaged-gain splits\". The three heatmaps correspond to the same three conditions. The ghost region between the two main modes is prominent. The presence of an outlier has a less noticeable effect on the overall anomaly score landscape compared to the top row.*\n***\n\nIn this particular example, these ghost regions and the leverage of local outliers are not a problem for either method, but in real larger-dimensional datasets it could result in undesirable patterns if the sub-sample of data that a tree uses is not too representative. It might also pose a problem if a model is to be used for \"novelty detection\" - that is, to identify anomalies in new data to which the model will not be fit, as opposed to identifying outliers within the same that that is available for producing a model. ", "mimetype": "text/plain", "start_char_idx": 19634, "end_char_idx": 20740, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "81559909-fc40-4a1a-a287-797c32fdabd3", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "696a7fa4-0a94-4fdf-b821-9e2ec8cc3147", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "cf73686b11c957021368b2b1021f4e2c36a08c53047c4e5c24c6d5495f4f6e9d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8f3d2407-ac05-4aca-b916-5807793a28f8", "node_type": "1", "metadata": {}, "hash": "de390060e8345f9255332a83851186a46c6321d3526fa2ad847e4a66e28b7b66", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"Novelty detection\" is however not the focus of this work.\n\nIn contrast to the gain criterion from SCIFOREST which is set on a random linear combination of a few variables, DET and related models such as OCRF and GIF will look at a larger part or even the entirety of the multivariate distribution of the data when evaluating a partition, and their criteria tend to favor partitions which divide the data more evenly in the earlier branches as opposed to leaving only a few points at one side of a division.\n\nDET\u2019s splitting criterion and scoring metric do not directly relate to the concept of isolation, and its intended use-case in [17] was not exactly anomaly detection either, but as can be seen from their experiments and from the criterion that is maximized, the splits it generates will implicity isolate outlier observations faster (taking fewer splits) as they are assigned to higher-volume regions, which are in turn defined by fewer splits than smaller-volume regions. In [10] they found isolation depth to be a useful scoring metric after generating partitions by a density-based criterion, although the same density score from DET can also be used as an anomaly score (the lower, the more anomalous), thereby avoiding the issue of having to extrapolate a depth remainder.\n\nJust like SCIFOREST, DET also tends to separate easily-divisible multimodal distributions quickly and to be relatively insensitive to the presence of local outliers in the data, but without suffering from the issue of ghost regions:\n\n***\n**Figure 4: Anomaly scores from DET in randomly-generated bimodal data.**\n\n*Description: A row of three heatmaps titled \"DET inverse predicted densities\". ", "mimetype": "text/plain", "start_char_idx": 20740, "end_char_idx": 22420, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "8f3d2407-ac05-4aca-b916-5807793a28f8", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "81559909-fc40-4a1a-a287-797c32fdabd3", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "dde3fda0e3c2a4efb42807769503af0a96919c8c8543b2c2eedfdc2520fa8e7d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b8ec4c37-1cb5-45d0-941a-b8eb5eb49ad6", "node_type": "1", "metadata": {}, "hash": "e70e2ef29b8ba72f681e940299b8a83e04b3e1bf3158940cdc94d481e4633839", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The heatmaps correspond to \"No outlier\", \"Outlier at top-left\", and \"Outlier at bottom-right\". The two modes of the bimodal data are shown as distinct high-density (low anomaly) rectangular regions. The space between and around them has a uniform high anomaly score. ", "mimetype": "text/plain", "start_char_idx": 22420, "end_char_idx": 22687, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b8ec4c37-1cb5-45d0-941a-b8eb5eb49ad6", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8f3d2407-ac05-4aca-b916-5807793a28f8", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "4daf19f1f0128fe69a42bee13bfcdc1c8a339ae84b67f1621ccdc213576dda79", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b9cc6047-9fc4-4a3a-9da0-fe28aaa36c2b", "node_type": "1", "metadata": {}, "hash": "3f65d49e26831e7041538571f16317d633049b3d3f7dc4d458220ecb54f4b91e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The presence of an outlier does not visibly alter the heatmaps.*\n***\n\nUnfortunately, it also tends to produce little discrimination in scores among non-extreme values, perhaps even less so than SCIFOREST. A logical thought to remedy this issue would be to employ a \"forest\" of DETs with sub-sampled observations just like IFOREST and without pruning the trees as originally proposed, but this does not eliminate the issue either:\n\n***\n**Figure 5: Anomaly scores from an ensemble of DETs with subsampled data, in randomly-generated bimodal data.**\n\n*Description: A row of three heatmaps titled \"DET forest, inverse predicted densities\". ", "mimetype": "text/plain", "start_char_idx": 22687, "end_char_idx": 23323, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b9cc6047-9fc4-4a3a-9da0-fe28aaa36c2b", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b8ec4c37-1cb5-45d0-941a-b8eb5eb49ad6", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "6c72825379e8f76f9f5468273d11e5af7e450c57b2e9e8953df06e61c038a2ca", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "01282845-a4d2-4e43-96df-fc5ebac1f0d7", "node_type": "1", "metadata": {}, "hash": "165510e38871e4dea6e6859e1422cfc09a5c044015956f88ad4e75622742ff19", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The heatmaps correspond to \"No outlier\", \"Outlier at top-left\", and \"Outlier at bottom-right\". Similar to Figure 4, they show two low-anomaly regions for the modes, but the boundaries are fuzzier due to the ensemble averaging. ", "mimetype": "text/plain", "start_char_idx": 23323, "end_char_idx": 23550, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "01282845-a4d2-4e43-96df-fc5ebac1f0d7", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b9cc6047-9fc4-4a3a-9da0-fe28aaa36c2b", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "916e51743bfa4b9cfb34619ebbf11e5faa37a7a938740a50f58ac74ac155df2e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "14dfea70-57a5-4645-b7cb-73c12a218b93", "node_type": "1", "metadata": {}, "hash": "75da197ae3dcefe590b238bff065da6025b3475cb959bf36d70ebc3ff531048e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The presence of an outlier still does not create a distinct high-anomaly spot at its location.*\n***\n\nAs another IFOREST variation, the RRCF model from [11] does not look at guiding the split threshold selection, but at guiding the selection of variable to split, doing so with a probability proportional to the range of each variable at a given node and relying on averaging out many randomized choices instead of always aiming for the best one as DET tries to do.\n\nSuch a criterion tries to address the issue of producing splits which are not helpful for discriminating outliers, but does so very differently from other methods. Variable selection is not a new idea for IFOREST - for example, in [14] they briefly mention using kurtosis as a variable screener, selecting only the top variables ranked by kurtosis to be included in a model, while SCIFOREST tries many variables at random in order to identify good candidates and DET tries all of them deterministically. RRCF is different in the sense that it relies on averaging out errors, introducing less-granular guidance to the split choices.\n\n", "mimetype": "text/plain", "start_char_idx": 23550, "end_char_idx": 24649, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "14dfea70-57a5-4645-b7cb-73c12a218b93", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "01282845-a4d2-4e43-96df-fc5ebac1f0d7", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "6a211ffe8fa824775af4ca87d6acdd07d73912004227c3edaabe4a1eaf4da399", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b09479a9-982e-4827-81f7-4cb8c06cfb9f", "node_type": "1", "metadata": {}, "hash": "573ff24f38e2d243a079aa4c89519c39e62a662325202d6706b74ea2f8fd2ed5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In theory, RRCF suffers from many of the same issues as IFOREST as outlined in e.g. [12] and [2], and visualizing its calculated anomaly scores on randomly-generated points that exemplify an extreme pattern (such as inner and outer rings, sine waves, etc.) would not look too differently from the scores produced by IFOREST - for example, in the bimodal random numbers from earlier plots, it would not identify the top-left or bottom-right outliers as the most anomalous observations, although it would rank them as relatively more anomalous compared to the rest than IFOREST would. In practice however, RRCF has demonstrated improved performance metrics when applied on real datasets of varying characteristics.\n\n## 5 Better data separations\n\nIdeally, one would want the splits made by an isolation tree to assign more points to regions where the multivariate density or likelihood of the data distribution is higher and to make these regions as narrow as needed, or under an alternative view to group together observations which are more similar, making the points in a node closer and closer further down each tree, which in broad terms requires making splits on good boundaries across the right variables. This kind of problem has been approached from different angles in different problem domains such as anomaly detection, clustering, or approximate nearest neighbor search, using different measuring criteria. DET looked at volume, RRCF at ranges of variables, SCIFOREST at variance, [14] briefly looked at kurtosis, and given the logic of IFOREST one might also think of looking at other measurements of deviation from a uniform distribution. From all these criteria, the most natural (esp. for multimodal distributions) and most widely used in different algorithms is perhaps variance, but the way in which other algorithms use it is rather different from SCIFOREST.\n\nTypically, supervised decision trees (e.g. [16] and [3]) make a trade-off in their guiding heuristic between branch purity (homonegenity of the points in a given partition) and number of observations that are assigned to each branch of a split. DET and similar also make such a trade-off implicitly, while SCIFOREST and RRCF do not look at this aspect.\n\nMore concretly, in the case of regression trees, it is typical to use as splitting criterion a pooled standard deviation gain, which is slightly different from the averaged standard deviation gain used by SCIFOREST\n\ngain_pooled = (\u03c3_all - (n_left\u03c3_left + n_right\u03c3_right)/(n_left+n_right)) / \u03c3_all\n\nThe \"Fair-Cut Forest\" or FCF from [7] applied this pooled gain criterion on random linear combinations of variables in order to determine splits by these same linear combinations, similarly to SCIFOREST but with the goal of finding neighbors for missing value imputations rather than producing anomaly scores. While not the original goal of FCF, this split guiding criterion turns out to produce splits that are also useful for outlier detection as will be seen in the next sections, as these splits tend to represent more natural separations, which can come especially useful in clustered or multimodal distributions (as opposed to outliers represented by extreme values which could be identified by e.g. kurtosis or deviation w.r.t a uniform distribution):\n\n***\n**Figure 6: Splits chosen by each criteria in randomly-generated numbers. ", "mimetype": "text/plain", "start_char_idx": 24649, "end_char_idx": 28016, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "b09479a9-982e-4827-81f7-4cb8c06cfb9f", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "14dfea70-57a5-4645-b7cb-73c12a218b93", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "0bc80367601842d88d6c86d93ed02c4c8dd262c197fecb692b127a927a882129", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dd41b458-9369-4973-ac48-8cff4561e77b", "node_type": "1", "metadata": {}, "hash": "1e53fad67fce8c60e3d89e16f194e2cba7a83b0439523039c639ac0fa52ace18", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the left picture, the density-chosen point matches with that of pooled gain, while in the center picture it closely matches with that of averaged gain.**\n\n*Description: Three histograms are shown.\nThe first, \"Random Numbers ~Normal(0,1)\", shows a normal distribution. Three vertical lines indicate the split points chosen by \"Averaged gain\", \"Pooled gain\", and \"Density\". \"Pooled gain\" and \"Density\" are very close to the peak, while \"Averaged gain\" is slightly off-center.\nThe second, \"Random Numbers ~Gamma(1,1)\", shows a skewed gamma distribution. Here, \"Averaged gain\" and \"Density\" are very close, near the mode, while \"Pooled gain\" is further to the right.\nThe third, \"Gaussian mixture\", shows a bimodal distribution. All three criteria choose a split point in the valley between the two modes, with \"Pooled gain\" and \"Density\" being very close and \"Averaged gain\" slightly offset.*\n***\n\nIf the best possible pooled gain from a split point is evaluated across different variables, those in which clusters are more easily formed or in which separations are more clear will result in a higher gain, perhaps making it also a potential heuristic for variable selection.\n\nIn a way, pooled gain applied on a single variable or linear combination is trying to \"predict\" the same values that it is input (using group means as \"prediction\"), and the groups that it produces will in expectation become more and more homogeneous after each split, resulting in something similar to an autoencoder; but it is a myopic criterion: if measuring a global squared error objective across all variables, \"predictions\" (per-column means in each node) are not guaranteed to improve after each step. One could also think of minimizing instead a pooled gain criterion calculated across all variables in the data, but such a criterion, while perhaps reasonable in theory, would in practice result in much slower evaluation and would perhaps lead to sub-optimal splits in the presence of multicollinearity. ", "mimetype": "text/plain", "start_char_idx": 28016, "end_char_idx": 30006, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "dd41b458-9369-4973-ac48-8cff4561e77b", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b09479a9-982e-4827-81f7-4cb8c06cfb9f", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "e72fa16ed27ab237af98addbc85476b660dba742bb9e22b6a059dcdf59500fba", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a5d69b5c-18a7-4fed-b70d-676fb149f092", "node_type": "1", "metadata": {}, "hash": "710d38be0c225d12775d3ef9ba623d48a246981986113a29f149e42c9b3f6776", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A shorter and myopic gain calculated on one or a few variables can nevertheless rely on averaging out errors across many runs for better results.\n\nCompared to SCIFOREST, FCF can also be reasonably fast at isolating scattered outliers within each tree, but the partitions that it chooses to isolate them are rather different and can result in much larger variability in the final results according to the data sub-samples that each tree uses:\n\n***\n**Figure 7: Anomaly scores from FCF in randomly-generated bimodal data**\n\n*Description: A 2x3 grid of heatmaps shows anomaly scores from FCF.\nThe top row is titled \"Fair-Cut Forest (3 trials), no sub-sampling\". ", "mimetype": "text/plain", "start_char_idx": 30006, "end_char_idx": 30664, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "a5d69b5c-18a7-4fed-b70d-676fb149f092", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dd41b458-9369-4973-ac48-8cff4561e77b", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "0bae184e0b5caea4908d812f6a8bf78727f871f2fb2b90933f43d36431a01434", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "17f9af2f-6db7-4a90-b737-4578427a9a5e", "node_type": "1", "metadata": {}, "hash": "f35376575b783b4c9efd147d15513d20ab2a6ae10c491b69fef6d792e1a24b4d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The three heatmaps (\"No outlier\", \"Outlier at top-left\", \"Outlier at bottom-right\") show significant variation between trials. The two modes are generally identified as low-anomaly regions, but the shape and intensity of anomaly scores vary.\nThe bottom row is titled \"Fair-Cut Forest (3 trials), with sub-sampling\". ", "mimetype": "text/plain", "start_char_idx": 30664, "end_char_idx": 30980, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "17f9af2f-6db7-4a90-b737-4578427a9a5e", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a5d69b5c-18a7-4fed-b70d-676fb149f092", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "e8e2fd2ae8c86013158d32679e251bd23eae7f915e1a620d6cf4d76bf514d02e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "07de8bea-7f27-4e25-ac4f-f6372ffd43cf", "node_type": "1", "metadata": {}, "hash": "35fe31c547b73b8bea22dd5b74125a9607a12035f6ecb76127cbf1f0d48bd5b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The heatmaps here also show high variability between trials, and the patterns are less clear than in the top row, reflecting the effect of sub-sampling.*\n***\n\nThe tree structure produced by splits that follow this pooled gain criterion is also different from that of IFOREST - in the case of uniformly-random data, the optimal split would always correspond to assigning half of the points to one branch, leading to an expected isolation depth of E[d(m)] = log\u2082m when m is a power of 2, which is strictly smaller than the expected depth for uniformly random splits (given by E[d(m)] = 2(H\u2098 - 1), where H\u2098 is the m-th harmonic number) for m > 2, but with a structure that produces larger trees (containing more nodes) at the same height as the equivalent IFOREST:\n\n***\n**Figure 8: Expected isolation depth for 5 uniform points under pooled gain**\n\n*Description: A diagram shows a binary tree structure for 5 points. A root node splits into two children. ", "mimetype": "text/plain", "start_char_idx": 30980, "end_char_idx": 31932, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "07de8bea-7f27-4e25-ac4f-f6372ffd43cf", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "17f9af2f-6db7-4a90-b737-4578427a9a5e", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "e3eb4c460d7fb943892f81ad29364ac85c57aca61281a3c903a8faf20fccf2c3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9f37bd49-0038-4227-a635-49fa9ac38492", "node_type": "1", "metadata": {}, "hash": "04ea3c250c785d5ff75d3633cf640f1b3e4bc3e3159d135cf6d4630f707e6d45", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The left child has 2 leaf nodes. ", "mimetype": "text/plain", "start_char_idx": 31932, "end_char_idx": 31965, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "9f37bd49-0038-4227-a635-49fa9ac38492", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07de8bea-7f27-4e25-ac4f-f6372ffd43cf", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "f36aeab490373b4671122d82d47917295c8a52e2443dc675bb2810df1f973672", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "43f70fe2-ff71-45c3-8a0b-b409cf3ed4b6", "node_type": "1", "metadata": {}, "hash": "2bb1d5f73ee63b2514895a34a6a195f8c044729abe3a0e704d351f62560a7738", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The right child splits again, leading to 3 leaf nodes. The calculation `E[d(5)] = (2+2+2+3+3)/5 = 2.4` is displayed.*\n***\n\n## 6 Hyperparameters under pooled gain\n\nIn [15] they kept most of the same IFOREST hyperparameters for the proposed SCIFOREST algorithm, adding a randomized trial of many linear combinations on top. These same designs might not be the most optimal for FCF when used for anomaly detection however, and are rather different from what DET and OCRF used. In the case of FCF, it should be taken into consideration that:\n\n*   If making splits by an averaged gain criterion, typically most of the cases will assign a single observation to one of the branches, and it could take many trials or evaluations across columns or linear combinations to choose a split that puts more than one observation in the smaller branch, which is not the case for the pooled gain criterion. What's more, if the split is performed on a linear combination of variables, it is typically enough for at least one of them to not be irrelevant in order for the linear combination to produce helpful splits.\n*   In IFOREST it was concluded that 100 trees was enough to get convergent results, but the splits generated by a pooled gain criterion on a sub-sample of the data have more expected variability, thus perhaps more trees would be needed to reach convergent results, especially in larger datasets.\n*   Both IFOREST and SCIFOREST used sub-sampling with 256 observations per tree, which in the case of IFOREST is helpful for dealing with some of the inherent problems in the method, but FCF might not suffer from the exact same problems.\n*   Both IFOREST and SCIFOREST chose a maximum depth equal to that of balanced-tree height as terminating criterion, but in the case of standardized pooled gain, it is also possible - and perhaps a more reasonable choice - to set this termination criterion on the gain itself, with nodes in which the best possible gain is less than some pre-determined acceptance level (e.g. 25%) potentially being set as terminal nodes and a remainder depth extrapolated.\n\nA small experiment with the \"SpamBase\" dataset would suggest that deeper trees are beneficial, regardless of the split criterion that is used:\n\n| Table 2: Results on \"SpamBase\" dataset with different termination criteria | | | |\n| :--- | :--- | :--- | :--- |\n| **Model** | **Termination** | **AUROC** | **Nodes** |\n| IFOREST | depth \u2265 8 | 0.6405 | 22,346 |\n| IFOREST | depth \u2265 16 | 0.6545 | 60,514 |\n| IFOREST | isolation | 0.6926 | 184,032 |\n| FCF | depth \u2265 8 | 0.5897 | 44,100 |\n| FCF | depth \u2265 16 | 0.6112 | 114,606 |\n| FCF | gain < 0.5 | 0.6197 | 132,694 |\n| FCF | isolation | 0.6220 | 174,960 |\n\nIncreasing the depth however also increases the standard error for the expected isolation depth that each observation would have:\n\n***\n**Figure 9: Average standard error for expected isolation depth of each observation**\n\n*Description: A 2x2 grid of line plots titled \"Standard error for average isolation depth (SpamBase Dataset)\". Each plot shows \"Average standard error\" on the y-axis versus \"Number of trees\" on the x-axis (from 0 to 300).\n", "mimetype": "text/plain", "start_char_idx": 31965, "end_char_idx": 35101, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "43f70fe2-ff71-45c3-8a0b-b409cf3ed4b6", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9f37bd49-0038-4227-a635-49fa9ac38492", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "18260ecee8c4d86539f518573569ac73afa8d7818aa7fd2e3a87f1c6dd55f408", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "166c5bdc-aeb7-42a1-ba4e-24180776565c", "node_type": "1", "metadata": {}, "hash": "60b6f40c50c9e633098da137713e6d139062a2e76144fdbc4512e7b2617856ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The top-left plot, \"iForest (max depth)\", shows the error quickly decreasing and stabilizing around a low value.\nThe top-right plot, \"iForest (unlimited)\", shows a similar but slightly higher stable error.\nThe bottom-left plot, \"FCF (max depth)\", shows a higher initial error that decreases with more trees but remains higher than for iForest.\nThe bottom-right plot, \"FCF (unlimited)\", shows the highest error, which also decreases but remains significantly higher than the others, indicating more trees are needed to stabilize the estimate.*\n***\n\nThis increase in the standard error can nevertheless be easily offset by an increase in the number of isolation trees, at the expense of longer running times. For example, reaching the same average standard error per observation for the expected isolation depth as in IFOREST with 100 trees and limited depth under FCF with unlimited depth would require a bit over 200 trees in this particular dataset. Fitting such a model (trees growing until full isolation, twice as many trees) is roughly an order of magnitude slower than if using the hyperparameters proposed in [14], but with a careful software implementation, this is still much faster than many competing methods for anomaly detection across several datasets as will be seen in the next section.\n\nIn [15] the suggestion was to make splits on random linear combinations of 2 variables, trying 10 such random linear combinations at each node. ", "mimetype": "text/plain", "start_char_idx": 35101, "end_char_idx": 36549, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "166c5bdc-aeb7-42a1-ba4e-24180776565c", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "43f70fe2-ff71-45c3-8a0b-b409cf3ed4b6", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "42eb06b35762d6d6e3e0a2750c7f82933c5905be3698a0bebd9f2b6334c377da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d41045ca-af5f-4e53-8673-3460db662e32", "node_type": "1", "metadata": {}, "hash": "271608b43f58bbddb8c3b5b2f125cfaa4b5d12fdff10bb072948ab6d195dbe4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Some short experiments would suggest that 10 trials is perhaps too much for a pooled gain criterion, with better performance being achieved when this number is decreased, and only a small difference from using hyperplanes vs. axis-parallel splits:\n\n| Table 3: Varying the number of trials for different variables or random linear combinations of several variables in FCF, results on \"SpamBase\" dataset | | | |\n| :--- | :--- | :--- | :--- |\n| **Variables per split** | **Trials** | **AUROC (256 samples)** | **AUROC (no subsampling)** |\n| 1 | 1 | 0.7312 | 0.7095 |\n| 1 | all | 0.4405 | 0.4697\\* |\n| 2 | 1 | 0.7245 | 0.6950 |\n| 2 | 3 | 0.6220 | 0.5868 |\n| 2 | 10 | 0.4986 | 0.4861 |\n| 5 | 1 | 0.6893 | 0.6683 |\n| 5 | 3 | 0.6696 | 0.6199 |\n| 5 | 10 | 0.6127 | 0.5619 |\n\n* This case was sampled with replacement in order to avoid generating the exact same splits in each tree.\n\n| Table 4: Varying the number of trials for different variables or random linear combinations of several variables in FCF, results on \"Satellite\" dataset | | | |\n| :--- | :--- | :--- | :--- |\n| **Variables per split** | **Trials** | **AUROC (256 samples)** | **AUROC (no subsampling)** |\n| 1 | 1 | 0.8368 | 0.7261 |\n| 1 | all | 0.8057 | 0.7152\\* |\n| 2 | 1 | 0.8186 | 0.7465 |\n| 2 | 3 | 0.8414 | 0.7451 |\n| 2 | 10 | 0.8298 | 0.7312 |\n| 5 | 1 | 0.8246 | 0.7544 |\n| 5 | 3 | 0.8235 | 0.7618 |\n| 5 | 10 | 0.8080 | 0.7509 |\n\n* This case was sampled with replacement in order to avoid generating the exact same splits in each tree.\n\nThe number of samples to take for each tree has a similar influence as in IFOREST, but a deeper look at some datasets would reveal that the optimal sample size for some datasets can be much smaller than the 256 proposed in [14] which was also used in others such as [12] or [15]:\n\n***\n**Figure 10: AUROC by sample size and model characteristics in \"SpamBase\" dataset**\n\n*Description: Two line plots are shown side-by-side. Both plot AUROC versus Sample size (on a log scale from 8 to 2048). Different colored lines represent different numbers of \"Variables per split\" (1, 2, 5).\nThe left plot, \"AUROC by sample size, SpamBase datase (Pooled gain splits)\", shows that for all variable settings, the AUROC peaks at a sample size of 32 or 64 and then decreases as the sample size grows.\nThe right plot, \"AUROC by sample size, SpamBase datase (Uniformly-random splits)\", shows a similar trend where AUROC peaks at a small sample size (around 64) and then declines.*\n***\n\nYet in other datasets, sub-sampling is not helpful, with trees fitted to the full number of rows achieving better performance:\n\n***\n**Figure 11: AUROC by sample size and model characteristics in sub-sampled \"Forest-Cover\" dataset**\n\n*Description: Two line plots similar to Figure 10, but for the ForestCover dataset. The sample size on the x-axis goes up to 8192.\nThe left plot, \"AUROC by sample size, ForestCover dataset... (Pooled gain splits)\", shows that AUROC generally increases with sample size for all variable settings, with the best performance achieved at the largest sample sizes.\nThe right plot, \"...(Uniformly-random splits)\", shows a similar trend, with AUROC consistently improving as the sample size increases toward the full dataset size.*\n***\n\nAs such, a potentially safe combination of hyperparameters for using FCF in anomaly detection would be as follows:\n\n*   Trees grown until full isolation (only one point is present in a given branch of a split) or until no further split is possible, in which case a remainder is extrapolated.\n*   200 trees.\n", "mimetype": "text/plain", "start_char_idx": 36549, "end_char_idx": 40086, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d41045ca-af5f-4e53-8673-3460db662e32", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "166c5bdc-aeb7-42a1-ba4e-24180776565c", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "a83759952069f01173648502833c0d5a5c243dcb4322d30874c119d7b5bde0b0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "46ffbce1-0a3d-4395-848f-7741bdcbef5c", "node_type": "1", "metadata": {}, "hash": "32dbcfa4ddc05be916aa52b8fcd0d669a5af199d6ca8ddce328c186dd607f9cf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "*   A sample size of 32 to 256 points chosen without replacement to be used by each tree, but with numbers much smaller or much larger than this resulting in better results in some datasets (perhaps smaller numbers being better for multi-modal datasets).\n*   Splitting data according to a threshold on a random linear combination of 2 variables, but with a larger number of variables and with single-variable (axis-parallel) splits producing better results in some datasets.\n*   Only one trial of a uniformly-randomly-chosen candidate variable or random linear combination to try at each node.\n\nThe full procedure for producing trees and anomaly scores is outlined below. ", "mimetype": "text/plain", "start_char_idx": 40086, "end_char_idx": 40758, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "46ffbce1-0a3d-4395-848f-7741bdcbef5c", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d41045ca-af5f-4e53-8673-3460db662e32", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "f5556fc931f99c00d57801de887303a0af765d42e3a101197e7f2bb063a17b2d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "914018de-2f3e-46bb-a260-19e457dbf0c0", "node_type": "1", "metadata": {}, "hash": "d8fe5f8488a1e71626eb897f6ab71399e5cb93c25947befab6e5374672cf3cc6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The implementation produced here is made open source and freely available\u00b3.\n\n\u00b3https://www.github.com/david-cortes/isotree\n\n**Algorithm 1 FairCutTree**\n\n**Inputs** Input data points X\u2098\u2093\u2099, number of splitting variables p, current depth d\n1: **if** m = 1 **then**\n2:   Set as terminal node with depth d\n3: **if** each of the n columns in **X** has the same value across all of its rows **then**\n4:   Set as terminal node with depth d + E[depth(m)]\n5: Initialize vector **z** := 0\u1d50\n6: **for** 1..p **do**\n7:   Choose a variable v uniformly at random from [1,n] such that it contains more than 1 unique value within **X**, and define **y** = **X**[:,v] (vector with the values of **X** in that variable)\n8:   Draw a random coefficient c ~ Normal(0, 1)\n9:   Update **z** := **z** + c * **y** / \u03c3\u1d67\n10: Find the point s that minimizes\n    (m_left\u03c3_zl + m_right\u03c3_zr) / (m_left + m_right)\n    Where **z**_l = {z \u2208 **z** | z \u2264 s}, **z**_r = {z \u2208 **z** | z > s}, and \u03c3_z is the standard deviation of **z**\n11: Define **X**_l = {x\u1d62 \u2208 **X** | z\u1d62 \u2264 s} and **X**_r = {x\u1d62 \u2208 **X** | z\u1d62 > s}\n12: Set Node_L = FairCutTree(**X**_l, p, d + 1) and Node_R = FairCutTree(**X**_r, p, d + 1)\n\n---\n\n**Algorithm 2 Fair-Cut Forest**\n\n**Inputs** Input data points X\u2098\u2093\u2099, number of splitting variables p, number of trees t, sample size s\n1: **for** 1..t **do**\n2:   Choose a set S of s points uniformly at random from [1, m] without replacement, and set **X**_S = {x\u1d62 \u2208 **X** | i \u2208 S}\n3:   Set Tree\u1d62 = FairCutTree(**X**_S, p, 0)\n4: Calculate q = E[depth(m)]\n5: **return** The generated set T of t trees and q.\n\n---\n\n**Algorithm 3 TreeScore**\n\n**Inputs** Input point vector **x**_n, tree node N\n1: **if** N is a terminal node **then**\n2:   **return** The associated depth d from N\n3: **else**\n4:   initialize z := 0\n5:   **for** v = 1..p from the variables v \u2208 N **do**\n6:     Update z := z + c\u1d65 * y\u1d65 / \u03c3\u1d67\u1d65 with the c\u1d65, y\u1d65 and \u03c3\u1d67\u1d65 that were determined for variable v in N\n7:   **if** z \u2264 s from the optimal s in N **then**\n8:     **return** TreeScore(**x**, Node_L) from the nodes in N\n9:   **else**\n10:    **return** TreeScore(**x**, Node_R) from the nodes in N\n\n---\n\n**Algorithm 4 ScorePoint**\n\n**Inputs** Input point vector **x**_n, forest of t fair-cut trees **T**, expected isolation depth q\n1: Initialize d = 0\n2: **for** i = 1..t **do**\n3:   Update d := d + ScoreTree(**x**, Node\u2080 from T\u1d62)\n4: **return** 2^-( (d/t) / q )\n\n## 7 Evaluating different methods\n\nThe variation of the \"Fair-Cut forest\" algorithm or FCF proposed here was compared against IFOREST, some of its variations, and other competing methods for anomaly detection, including:\n\n*   The original \"isolation forest\u201d or IFOREST from [14], reimplemented according to the paper and sharing the same codebase as the FCF here. The hyperparameters used were the ones suggested in [14] (100 trees, 256 samples per tree, maximum depth of 8), and most of the other algorithms are based around these same hyperparameters.\n", "mimetype": "text/plain", "start_char_idx": 40758, "end_char_idx": 43707, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "914018de-2f3e-46bb-a260-19e457dbf0c0", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46ffbce1-0a3d-4395-848f-7741bdcbef5c", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "e6adc08b1d6183e0267927fa7ba8f174b18815004b8b1e42825a05d86dc259a8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c8d66ef0-a54f-4184-9ffc-8184f3d2098d", "node_type": "1", "metadata": {}, "hash": "3b14643098a10e1d193126083e175e82032058d6fe99a3ab365d5232134c19f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "*   The original IFOREST but with the same hyperparameters set for FCF (200 trees, unlimited depth, marked as IF-U).\n*   The \"extended isolation forest\" or EIF from [12], using both the authors' implementation\u2074 (EIF-O) and and independent implementation (EIF-T). Note that the implementation here differs from the original EIF in one important aspect: it standardizes variables by calculating the standard deviations at each node rather than just at the beginning of the tree. The extension level was set to 1 (splitting by 2 variables at a time) as recommended by the authors, plus the same default hyperparameters from IFOREST.\n*   The \"robust random-cut forest\u201d or RRCF from [11], using a publicy-available implementation\u2075 that uses the \"CoDisplacement\u201d metric as proposed in [11] for anomaly scoring (denoted as RRCF-C), and a different public implementation\u2076 that uses average isolation depth for anomaly scoring (denoted as RRCF-D). Note that both of them are pure-Python implementations, which makes them much slower than the rest despite the idea being in theory relatively fast to execute, and that the second implementation did not allow setting random seeds.\n", "mimetype": "text/plain", "start_char_idx": 43707, "end_char_idx": 44877, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "c8d66ef0-a54f-4184-9ffc-8184f3d2098d", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "914018de-2f3e-46bb-a260-19e457dbf0c0", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "f3c0e2dcf8e211d0f99dfef24247b1745044904ab5634bb43c90f89bcb3e913c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "330c7513-a0ad-4610-8327-041e5112bd9a", "node_type": "1", "metadata": {}, "hash": "17e667ced2443acf2cd66b4c4d5c9aa2b72b35da17af47e7e2cd2c26843333af", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "*   The \"density estimation trees\" or DET from [17], using the implementation from MLPack\u2077.\n*   A \"forest\" (DEF) of 100 DETs using sub-samples of 256 points each, sampled without replacement, and the trees built without pruning, in order to make it directly comparable to IFOREST, with the final prediction averaged across these 100 DETs.\n*   The \"generalized isolation forest\" or GIF from [5], using the implementation provided by the authors\u2078 and the hyperparameters suggested in their web example.\n*   The \"one-class random forest\u201d or OCRF from [10], using the implementation provided by the authors\u2079.\n*   The SCIFOREST from [15], reimplemented according to their description (including e.g. range penalties at prediction time) and sharing the same codebase as FCF. Another variation with 200 trees grown until full isolation of every point was also explored (SCIF-U), driven by the expected isolation depth issue highlighted earlier. Note that the original IFOREST code from the authors\u00b9\u2070 (of both IF and SCIFOREST) included a similar decision criterion but it used only single-variable splits, and was thus not compared against here.\n*   The \"isolation nearest-neighbor ensembles\u201d or iNNE from [2], using one of the implementations from the authors\u00b9\u00b9, with hyperparameters \u03c8 = 32 and t = 100 as suggested in the reference. Note that this implementation did not allow setting random seeds and was ran only once.\n", "mimetype": "text/plain", "start_char_idx": 44877, "end_char_idx": 46293, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "330c7513-a0ad-4610-8327-041e5112bd9a", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c8d66ef0-a54f-4184-9ffc-8184f3d2098d", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "d7263c2386d4170d9114354805c820603e25b556546a9ee3137c245b0e21c590", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5a5f951a-ca4c-42ba-8f1f-7984826110cc", "node_type": "1", "metadata": {}, "hash": "2ace7b3e5af4cad1cf7345e65b57161019c4a475a802f8aea64e81753a2a0121", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "*   The \"local outlier factor\" or LOF from [4], using the implementation from scikit-learn\u00b9\u00b2.\n*   The \"one-class support vector machine\u201d or OCSVM from [19] in its linear and RBF kernel versions, using the implementation from scikit-learn\u00b9\u00b3.\n\nModels are evaluated on public datasets downloaded from the ODDS repository\u00b9\u2074 and from [6]\u00b9\u2075, representing a variety of outlier types (e.g. ", "mimetype": "text/plain", "start_char_idx": 46293, "end_char_idx": 46675, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "5a5f951a-ca4c-42ba-8f1f-7984826110cc", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "330c7513-a0ad-4610-8327-041e5112bd9a", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "054d009308d23f9d280c4121eba9e47e15b0c76cd47827e2e2dfe56091a17989", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3cdf510f-2547-47d4-9863-b2109a7445e4", "node_type": "1", "metadata": {}, "hash": "fe6be9bf5b1623801704564fea0eeb75da379f63100fb4f352869e4d469c6719", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "minority-class, extreme-valued, minority-mode) and problem domains. All datasets are taken in their raw form (which differs from how some of the references use them), prefering the version from ODDS\n\n\u2074https://github.com/sahandha/eif\n\u2075https://github.com/kLabUM/rrcf\n\u2076https://github.com/navdeep-G/robust-random-cut-forest\n\u2077https://www.mlpack.org/doc/mlpack-3.0.4/doxygen/dettutorial.html\n\u2078https://github.com/philippjh/genif\n\u2079https://github.com/ngoix/OCRF\n\u00b9\u2070https://sourceforge.net/projects/iforest/\n\u00b9\u00b9https://github.com/zhuye88/iNNE\n\u00b9\u00b2https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html\n\u00b9\u00b3https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html\n\u00b9\u2074http://odds.cs.stonybrook.edu\n\u00b9\u2075https://www.dbs.ifi.lmu.de/research/outlier-evaluation/\n\nwhen available. The evaluation is done by fitting said models to the full data under their default hyperparameters and producing outlier scores on this same data. ", "mimetype": "text/plain", "start_char_idx": 46675, "end_char_idx": 47635, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "3cdf510f-2547-47d4-9863-b2109a7445e4", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5a5f951a-ca4c-42ba-8f1f-7984826110cc", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "6daa2401990572451bdd7b688e73b687199423e89ebe1a30c72f21291e28f3f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a3c0ffc7-8cb9-469d-a673-12d1844c40e7", "node_type": "1", "metadata": {}, "hash": "e15f5dbc0da9960ac4556b50e8c3f61877d27bff3b56980a576d77a12eec5b23", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These scores are compared against the true labels for outlierness (which the models do not observe in their fitting procedures) in terms of area under the receiver-operating characteristic curve (ROC) and area under the precision-recall curve (PR), which as analyzed in [8] might be a more appropriate metric than the more commonly used ROC. Each model that uses randomization is fitted 10 times using different random seeds, and the result reported here is calculated as the mean across these 10 runs. ", "mimetype": "text/plain", "start_char_idx": 47635, "end_char_idx": 48138, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "a3c0ffc7-8cb9-469d-a673-12d1844c40e7", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3cdf510f-2547-47d4-9863-b2109a7445e4", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "856e93a28d4a4428dab0b56a62097cb6ab6ccb7c8b35c9dde7c64115157a08ca", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54777e2f-509d-49f4-b01e-74ed8508e7e0", "node_type": "1", "metadata": {}, "hash": "240cb6313b8684f31cdd42b17c4d89c33fa86ea3c0f6ff2138d5aa85338bcafd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For larger datasets, some of the methods were not compared against due to the long running times that some of them would require as the volume of data grows.\n\nExperiments were run on an AMD Ryzen 7 2700 CPU with 8 cores running at 3.2GHz, and times are reported in seconds taken for fitting a given model plus producing outlier scores from said model. Where possible, software was compiled under GCC version 10.3 with options \"-O3\" and \"-march=native\". Note however that, for larger datasets, the times for tree-based methods are dominated by the calculation of outlier scores, which was done with the same data format as the models (column-major order, double precision) and through the same software library that produced each model, but these times could be reduced significantly if, for example, a row-major format were used and the decision trees were pre-compiled (e.g. through software such as \"treelite\u201d\u00b9\u2076), which would make all tree-based methods look significantly faster (roughly 10 to 30 times faster in the larger datasets if the compilation times are not considered).\n\nWhile others such as [5] and [2] perform hyperparameter tuning in their experiments based on the true outlier labels, in the case of anomaly detection, this is a problematic aspect as such labels are not supposed to be available in contexts in which models like these would be employed, and it can tend to favor model types which are only good under fine-tuned parameters specific to each dataset without providing a clear picture of how generalizable such models really are. For example, models such as GIF or iNNE can show either one of the best or one of the worst performances in a given dataset depending on the hyperparameters used, while models such as IF or EIF are quite generalizable across datasets and outlier types under the same set of parameters.\n\n| Table 5: Datasets used for comparisons | | | |\n| :--- | :--- | :--- | :--- |\n| **Dataset** | **Rows** | **Columns** | **Outliers** |\n| Arrhythmia | 452 | 274 | 15% |\n| Pima | 768 | 8 | 35% |\n| SpamBase | 4,601 | 57 | 39.4% |\n| Satellite | 6,435 | 36 | 32% |\n| Pendigits | 6,870 | 16 | 2.27% |\n| Annthyroid | 7,200 | 6 | 7.42% |\n| Mnist | 7,603 | 100 | 9.2% |\n| ALOI | 50,000 | 27* | 3% |\n| Forest Cover | 286,048 | 10 | 0.9% |\n\n\\* This dataset contains a categorical variable. As most of the methods compared here do not work with categorical variables, it was left out for a fairer comparison.\n\n", "mimetype": "text/plain", "start_char_idx": 48138, "end_char_idx": 50582, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "54777e2f-509d-49f4-b01e-74ed8508e7e0", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a3c0ffc7-8cb9-469d-a673-12d1844c40e7", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "5c7cefb4724f5eaa50e99e6fc92d26bdf24b26aa2e361ff60f4195969c089712", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "132de388-c54d-452b-9c0c-9e118d4aaa4e", "node_type": "1", "metadata": {}, "hash": "e03556d6d1800b2fd9ad04f0fcd50af718ca5cacf3bb19e0b753d7e55f2c9328", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Some additional comments about these datasets:\n\n\u00b9\u2076https://treelite.readthedocs.io/en/latest/index.html\n\n*   **Arrhythmia:** variables are a good mixture of integral, continuous, binary, near-symmetric, and power tail. This was originally a multi-class classification dataset about different types of cardiac arrythmia, in which the non-arrythmic cases were mixed together with the most common arrythmias and the rest set as outliers.\n*   **Pima:** this was originally a binary-classification dataset in which the minority class was set as outliers.\n*   **SpamBase:** many variables have a skewed distribution with the majority of the rows having a value of exactly zero.\n*   **Satellite:** all variables have integer-only values, which can lead to earlier termination of tree-based methods due to ending with non-unique values in a node. This dataset was originally meant for multi-class classification, and was adapted for anomaly detection by mixing together frequent classes and uncommon classes, making it in a way a more multi-modal dataset in which outliers are those near less common modes, which is quite different from the other datasets.\n*   **Annthyroid:** most outliers can be differentiated through a single high-skew column. This dataset originally consisted of 3 classes which can be thought of as representing values \"low\", \"normal\", \"high\"; with \"low\" and \"high\" set as outliers (that is, outliers are a mixture of opposite groups, representing a relatively different scenario as in most other datasets).\n*   **Mnist:** variables are non-integer but with relatively few unique values, also leading to potential earlier termination. This dataset was originally about multi-class classification, and was converted to anomaly detection by including a majority of rows from one class and a minority of rows from another class (all outliers are the same class).\n*   **ALOI:** contains many very low-variance columns in which most of the points have the same value. Also contains some binary and power-tailed variables. ", "mimetype": "text/plain", "start_char_idx": 50582, "end_char_idx": 52613, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "132de388-c54d-452b-9c0c-9e118d4aaa4e", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "54777e2f-509d-49f4-b01e-74ed8508e7e0", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "197353198cbb1984bfa85b007729b916d4e81aea264d156cd188a8f470e564d9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cc298894-8e6f-49d3-8270-ee420dcf3fee", "node_type": "1", "metadata": {}, "hash": "ee6812997a2a89c013758da36bea6f822437ffdb7101b0502ee8742c9cf65145", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This is a dataset about images from different physical objects in which outliers constitute \"rare objects with 1-10 instances\u201d ([13]).\n*   **ForestCover:** just like \"Mnist\u201d, this was originally a multi-class classification dataset that was converted by sampling from a majority and a minority class.\n\n| Table 6: Results obtained by each method, part 1 | | | | | | | | |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| | **Arrythmia** | | | **Pima** | | | **SpamBase** | | |\n| **Model** | **ROC** | **PR** | **Time** | **ROC** | **PR** | **Time** | **ROC** | **PR** | **Time** |\n| IF | 0.7938 | 0.4599 | **0.00408** | 0.6795 | 0.4972 | **0.00537** | 0.6362 | 0.4757 | **0.00774** |\n| IF-U | 0.804 | 0.5012 | 0.0103 | 0.6807 | 0.5029 | 0.0119 | 0.6927 | 0.5242 | 0.0294 |\n| EIF-0 | 0.8052 | 0.4707 | 0.798 | 0.6628 | 0.5003 | 0.0784 | 0.6229 | 0.4791 | 0.61 |\n| EIF-T | 0.7986 | 0.4669 | 0.00735 | 0.6778 | 0.4970 | 0.00633 | 0.6596 | 0.5021 | 0.0149 |\n| SCIF | 0.6854 | 0.3368 | 0.0188 | 0.6130 | 0.4236 | 0.0172 | 0.4517 | 0.3801 | 0.0189 |\n| SCIF-U | 0.7333 | 0.3431 | 0.152 | 0.6565 | 0.4548 | 0.122 | 0.4223 | 0.3454 | 0.878 |\n| FCF | 0.8032 | 0.4842 | 0.0411 | **0.7362** | **0.5508** | 0.0363 | **0.7321** | 0.5694 | 0.281 |\n| RRCF-D | **0.8134** | 0.5177 | 10.5 | 0.6277 | 0.4809 | 12.1 | 0.7255 | **0.6317** | 65 |\n| RRCF-C | 0.7874 | 0.4279 | 3.96 | 0.5900 | 0.4307 | 3.09 | 0.5774 | 0.4924 | 4.08 |\n| DET | 0.6706 | 0.3496 | 0.0979 | 0.6042 | 0.4360 | 0.0321 | 0.3862 | 0.4391 | 0.415 |\n| DEF | 0.6845 | 0.3752 | 0.97 | 0.6081 | 0.4940 | 0.212 | 0.5999 | 0.4399 | 0.742 |\n| OCRF | NA* | NA* | 0.286 | 0.6644 | 0.4743 | 0.295 | 0.4335 | 0.3455 | 0.602 |\n| GIF | 0.8031 | **0.5184** | 1.47 | 0.6067 | 0.4627 | 0.076 | 0.6580 | 0.5451 | 0.217 |\n| iNNE | 0.6881 | 0.2776 | 0.1602 | 0.5947 | 0.4155 | 0.0687 | 0.4769 | 0.3698 | 0.1938 |\n| OCSVM-L | 0.5498 | 0.3144 | 0.02 | 0.2598 | 0.2417 | 0.0133 | 0.2349 | 0.2658 | 1.17 |\n| OCSVM-K | 0.7948 | 0.4843 | 0.0378 | 0.6580 | 0.4907 | 0.0275 | 0.5063 | 0.5062 | 1.75 |\n| LOF | 0.7891 | 0.4189 | 0.0322 | 0.5424 | 0.3727 | 0.00741 | 0.4597 | 0.3576 | 0.525 |\n\n\\* OCRF in some cases ended up producing the same outlier score for every single point, thus metrics could not be computed.\n\n| Table 7: Results obtained by each method, part 2 | | | | | | | | |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| | **Satellite** | | | **Pendigits** | | | **Annthyroid** | | |\n| **Model** | **ROC** | **PR** | **Time** | **ROC** | **PR** | **Time** | **ROC** | **PR** | **Time** |\n| IF | 0.7164 | 0.6624 | **0.013** | 0.9549 | 0.2268 | **0.0151** | 0.8300 | 0.2820 | 0.0126 |\n| IF-U | 0.7280 | 0.6431 | 0.0382 | 0.9635 | 0.3029 | 0.04 | 0.8385 | 0.3121 | 0.0518 |\n| EIF-0 | 0.6970 | 0.6849 | 0.808 | 0.9736 | 0.3616 | 0.536 | 0.7407 | 0.2675 | 0.393 |\n| EIF-T | 0.6800 | 0.6364 | 0.017 | 0.9592 | 0.3391 | 0.022 | 0.8207 | 0.2859 | 0.021 |\n| SCIF | 0.6083 | 0.5888 | 0.0285 | **0.9788** | **0.4110** | 0.0337 | 0.7715 | 0.4634 | 0.0267 |\n| SCIF-U | 0.7549 | 0.6916 | 0.356 | 0.9785 | 0.3552 | 0.209 | 0.9668 | 0.6594 | 0.721 |\n| FCF | **0.8253** | **0.7300** | 0.139 | 0.9662 | 0.2730 | 0.179 | 0.8712 | 0.3810 | 0.203 |\n| RRCF-D | 0.7270 | 0.6837 | 69 | 0.9374 | 0.2310 | 65 | 0.7109 | 0.2271 | 81 |\n| RRCF-C | 0.7089 | 0.5747 | 4.43 | 0.9198 | 0.2125 | 3.41 | 0.7477 | 0.2457 | 3.43 |\n| DET | 0.7070 | 0.5495 | 1.27 | 0.7088 | 0.0384 | 0.558 | 0.8910 | 0.2687 | 0.825 |\n| DEF | 0.7300 | 0.4644 | 0.973 | 0.8602 | 0.2583 | 0.517 | **0.9789** | **0.7147** | 0.612 |\n| OCRF | 0.7495 | 0.6568 | 0.711 | 0.8833 | 0.1667 | 0.776 | 0.8368 | 0.2094 | 0.613 |\n| GIF | 0.7561 | 0.5485 | 0.218 | 0.8501 | 0.0907 | 0.134 | 0.5342 | 0.0885 | 0.0679 |\n| iNNE | 0.6042 | 0.3892 | 0.189 | 0.8975 | 0.1064 | 0.1265 | 0.7047 | 0.1891 | 0.1309 |\n| OCSVM-L | 0.6759 | 0.4803 | 1.47 | 0.7652 | 0.1233 | 1.28 | 0.4857 | 0.0840 | **0.00125** |\n| OCSVM-K | 0.6669 | 0.6718 | 2.62 | 0.9599 | 0.3206 | 2.39 | 0.5727 | 0.1171 | 2.35 |\n| LOF | 0.5428 | 0.3754 | 0.784 | 0.4821 | 0.0368 | 0.972 | 0.7373 | 0.2055 | 0.0773 |\n\n| Table 8: Results obtained by each method, part 3 | | | | | | | | |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| | **Mnist** | | | **ALOI** | | | **ForestCover** | | |\n| **Model** | **ROC** | **PR** | **Time** | **ROC** | **PR** | **Time** | **ROC** | **PR** | **Time** |\n| IF | 0.8033 | 0.2608 | **0.0147** | 0.5375 | 0.0327 | **0.029** | 0.8509 | 0.0379 | **0.222** |\n| IF-U | 0.8167 | 0.2851 | 0.0474 | 0.5291 | 0.0319 | 0.211 | 0.8552 | 0.0388 | 0.935 |\n| EIF-0 | 0.8150 | 0.2669 | 1.81 | 0.5428 | 0.0351 | 4.01 | 0.9047 | 0.0634 | 16.7 |\n| EIF-T | 0.8130 | 0.2762 | 0.0281 | 0.5428 | 0.0332 | 0.0755 | 0.8720 | 0.0445 | 0.48 |\n| SCIF | 0.8584 | 0.3864 | 0.0285 | 0.5192 | 0.0306 | 0.0698 | 0.7037 | 0.0154 | 0.405 |\n| SCIF-U | 0.8432 | 0.3762 | 0.316 | 0.5173 | 0.0317 | 7.31 | 0.7040 | 0.0157 | 11.3 |\n| FCF | 0.7871 | 0.2532 | 0.228 | 0.5256 | 0.0311 | 2.06 | 0.5463 | 0.0107 | 3.58 |\n| RRCF-D | 0.8204 | 0.2944 | 76 | 0.5484 | 0.0434 | 614 | 0.7269 | 0.0158 | 2393 |\n| RRCF-C | 0.7955 | 0.3026 | 4.45 | 0.5659 | 0.0441 | 20.1 | 0.8994 | 0.0465 | 77 |\n| DET | 0.8087 | 0.2645 | 1.37 | 0.5001 | 0.0317 | 0.0389 | 0.6679 | 0.0166 | 1256 |\n| DEF | 0.6390 | 0.2005 | 0.986 | 0.4868 | 0.0320 | 2.91 | 0.5875 | 0.0178 | 15.5 |\n| OCRF | NA* | NA* | 0.756 | 0.5026 | 0.0310 | 2.44 | 0.8344 | 0.0419 | 24 |\n| GIF | 0.7934 | 0.2412 | 0.642 | 0.5297 | 0.0406 | 0.244 | 0.7051 | 0.0281 | 0.796 |\n| iNNE | 0.8324 | 0.3641 | 0.4657 | **0.5814** | **0.0477** | 0.8570 | 0.9584 | 0.1871 | 2.2602 |\n| OCSVM-L | **0.9449** | **0.6709** | 3.45 | 0.5255 | 0.0412 | 148 | **0.9824** | **0.3904** | 3670 |\n| OCSVM-K | 0.8216 | 0.3231 | 5.4 | 0.5172 | 0.0460 | 162.63 | 0.6565 | 0.0125 | 4316 |\n| LOF | 0.6482 | 0.1874 | 1.33 | - | - | - | - | - | - |\n\n## 8 Discussion\n\nAs expected, there was no dominant outlier detection model across the datasets experimented with here, which consitute a mixture of different oulier types. Taking IF as a base, the only variation that sees consistently better or not-much-worse results across all types of datasets and outliers is EIF, at least when examined under the default hyperparameters of each model, which one might prefer to use in the absence of labels. ", "mimetype": "text/plain", "start_char_idx": 52613, "end_char_idx": 58917, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "cc298894-8e6f-49d3-8270-ee420dcf3fee", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "132de388-c54d-452b-9c0c-9e118d4aaa4e", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "6c63f532a332ea441dd1036902b9c5d187a426f56e104be8a72bd66097020803", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f631af66-33e4-4cbd-84cc-193e121478ca", "node_type": "1", "metadata": {}, "hash": "c9a4fbbd679835df1f3aab583240381c9d583a70a76caf2a830d0407b6c28d1b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Making the trees deeper and the forest larger also results in a small performance improvement at the cost of much longer running times, but these times are still competitive against other methods.\n\n", "mimetype": "text/plain", "start_char_idx": 58917, "end_char_idx": 59115, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "f631af66-33e4-4cbd-84cc-193e121478ca", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc298894-8e6f-49d3-8270-ee420dcf3fee", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "da6a38f58963395b185a8e1e35cb742c76ffe6c116d3a22bbe80377d63960170", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ce689420-20d5-44fa-aedd-43fc827f57fa", "node_type": "1", "metadata": {}, "hash": "5929610c1ab18964409df82304e6e2f3a375c0526c4cb9e1bd44eec6ec9ecf48", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "When these datasets are viewed in terms of outlier types however, one would notice that clustered outliers from multimodal datasets (e.g. \"Arrythmia\", \"Satellite\", \"SpamBase\", \"Annthyroid\") - oftentimes those of utmost interest but also the hardest to flag - are better identified under tree-based models than under other families, with non-uniformly-random splits providing an edge. In particular, the FCF model with hyperparameters chosen more appropriately for anomaly detection (as compared to its original application field) looks to be the best performer in these cases, followed closely by RRCF-D (which uses isolation depth for calculating anomaly scores instead of the \"co-displacement\u201d metric initially proposed for this model), but with a rather large advantage over RRCF in terms of computational efficiency (should be noted again that the RRCF implementation used here was not as optimized, but the procedure itself requires checking values across all columns of the data at each node, which makes it less scalable than other split guiding heuristics). For other types of outliers such as those of minority-in-binary-classes however (e.g. ", "mimetype": "text/plain", "start_char_idx": 59115, "end_char_idx": 60267, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ce689420-20d5-44fa-aedd-43fc827f57fa", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f631af66-33e4-4cbd-84cc-193e121478ca", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "d2e49624caae242fd03ce8a2c33b0caf3f9d0dc9cea623d3fa7cb1491224a8f6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dc59a1bb-1409-48f3-8fcc-d26f63a1e24d", "node_type": "1", "metadata": {}, "hash": "4dd39c5b6797a2f5bd84d347758505fdbec77b073f72f3e25762b0c36a788ba1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"Mnist\", \"ForestCover\"), FCF sees degraded performance compared to IF, and other families of less-local methods present better performance than either of them.\n\nSCIFOREST was found in [15] to provide an increase in AUROC under the majority of the datasets experimented with. The experiments here however show a very different picture once datasets with more varied characteristics are evaluated - for example, in the \"SpamBase\" dataset, SCIFOREST results in a very large performance drop compared to IF, even driving the AUROC below 0.5 (which is what random predictions would achieve). It should also be noted that these experiments failed to reproduce similar AUROC numbers under the same datasets used in [15], but once the depth limit was removed from the algorithm, the AUROC metrics became very similar to those reported there.\n\nIn [10], they report AUROC and AUPR metrics for many of the same datasets and baselines as in here, following a very similar methodology, but the results obtained in this experiment differ very significantly from those reported in [10], both for the proposed OCRF algorithm as well as for the baselines compared against - for example, [10] reports an AUROC of 0.850 in the SpamBase dataset for OCRF, while the experiments here reached an average AUROC of 0.4335 only, and while [10] found OCRF to outperform IF in 10 out of 12 datasets, that was the case only in 2 out of the 9 datasets experimented with in here (down to 1 dataset if considering IF-U). What's more, the proposed OCRF algorithm in some cases ended up producing the exact same outlier score for all observations, which made calculation of metrics not meaningful.\n\nComputation times in this experiment also showed how different implementations of the same algorithm can result in widly different execution speed, suggesting that the running times reported by previous works might not provide fair comparisons of the relative efficiency of algorithms. For example, [5] produced a very efficient software implementation of the proposed GIF algorithm, reporting GIF to run around an order of magnitude faster than EIF on the \"SpamBase\" dataset, and the experiments here could indeed confirm that it ran significantly faster than the EIF provided by its own authors, but once EIF is reimplemented with more attention to speed concerns, the comparison then flips as the EIF used here was an order of magnitude faster than GIF, despite doing extra computations at each step compared to the original EIF (when standardizing variables). Although not shown here, it was possible to obtain a further order of magnitude speed-up for prediction times in the larger datasets for models that use axis-parallel splits through pre-compilation of the trees (through e.g. ", "mimetype": "text/plain", "start_char_idx": 60267, "end_char_idx": 63021, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "dc59a1bb-1409-48f3-8fcc-d26f63a1e24d", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ce689420-20d5-44fa-aedd-43fc827f57fa", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "d93df4af04ccf725afb0f50d7e4767462e7d886bddbcf4dcc54c1b44afb49174", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "883d9a74-9e1d-450d-905f-c21314d983e0", "node_type": "1", "metadata": {}, "hash": "8a0b2b63f68e8a02fa0fb2b9111dad406e3a178e1a32ca0ee8258835a3633c33", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "the \"treelite\" software), but most of the software implementations compared here did not offer such functionality.\n\n## 9 Conclusions\n\nThis work analyzed different heuristics that have been proposed to guide the choice of splits in isolation forests, highlighting some behaviors and properties of interest of the models obtained by following different criteria; and along the way proposed a splitting rule based on uniformly-random column choice with deterministic split threshold selection which is obtained by maximizing a pooled information gain metric, aimed at increasing outlier detection capabilities in multi-modal datasets.\n\nThe proposed guiding heuristic was compared against other methods, including the original IFOREST algorithm as well as several variations of it that introduce non-uniformly-random split choice heuristics, and was found to offer increased performance for the outliers of utmost interest (clustered outliers from multi-modal datasets), at the expense of degraded performance in other classes of outliers.\n\nCompared to other methods, the proposed FCF algorithm not only showed increased performance as measured by ranking metrics, but also resulted in a more computationally-efficient procedure than other guiding heuristics, making it a promising algorithm for anomaly detection in datasets with multi-modal distributions.\n\n## References\n\n[1] Expected average depth in random binary tree constructed top-to-bottom. ", "mimetype": "text/plain", "start_char_idx": 63021, "end_char_idx": 64467, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "883d9a74-9e1d-450d-905f-c21314d983e0", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dc59a1bb-1409-48f3-8fcc-d26f63a1e24d", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "b63c0f8291a48ad99d54f9423e3413b6a268c025c0a75ac689ad331cf230fc22", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ee4f3a8e-f155-4aba-b665-e9ce6aa51aae", "node_type": "1", "metadata": {}, "hash": "c04c507d909248d1e039501acafd329b0c1bdd372c1b519910a464904b59944d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "https://math.stackexchange.com/questions/3333220/expected-average-depth-in-ra 2019. ", "mimetype": "text/plain", "start_char_idx": 64467, "end_char_idx": 64551, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ee4f3a8e-f155-4aba-b665-e9ce6aa51aae", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "883d9a74-9e1d-450d-905f-c21314d983e0", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "7af0eeca6cc2a3615247c5203582c6091c3fc71dcd5d39fbe5929025923f96c3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1ea283ae-f796-4ec1-9b25-4148a9d9057b", "node_type": "1", "metadata": {}, "hash": "928f4bd35acae998c9faa357c50f472116e24071dbd5debdd9be2d1b477c3ea1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[Online; accessed 9-September-2021].\n\n", "mimetype": "text/plain", "start_char_idx": 64551, "end_char_idx": 64589, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "1ea283ae-f796-4ec1-9b25-4148a9d9057b", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ee4f3a8e-f155-4aba-b665-e9ce6aa51aae", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "ece9e6ae417d6c70c81faf8f2bb28e9f2598067372696e528479051915d69b5b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5a9f6aae-ec7e-4c27-aa52-1f30d92be8b4", "node_type": "1", "metadata": {}, "hash": "f0e79ffd73c5aa8dabd855d31010f04a105d5cc1c04cd42fc8442cc658670af5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[2] Tharindu R Bandaragoda, Kai Ming Ting, David Albrecht, Fei Tony Liu, Ye Zhu, and Jonathan R Wells. Isolation-based anomaly detection using nearest-neighbor ensembles. Computational Intelligence, 34(4):968\u2013998, 2018.\n\n", "mimetype": "text/plain", "start_char_idx": 64589, "end_char_idx": 64810, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "5a9f6aae-ec7e-4c27-aa52-1f30d92be8b4", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1ea283ae-f796-4ec1-9b25-4148a9d9057b", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "adcdcfa96a39e43e31f1953ae1667f7cb901a5714bd7251a930d9cd672ae5be4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "358ae5d7-bde8-4561-aa2b-eba99ed39057", "node_type": "1", "metadata": {}, "hash": "b908437cd8328fc8cd6b2f140411bb76906cf93a6c999200c42e3ba2026a8d72", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[3] Leo Breiman. Classification and regression trees. Routledge, 2017.\n\n", "mimetype": "text/plain", "start_char_idx": 64810, "end_char_idx": 64882, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "358ae5d7-bde8-4561-aa2b-eba99ed39057", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5a9f6aae-ec7e-4c27-aa52-1f30d92be8b4", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "39b04bcddf48d6ce8d527d7f6f106de2277f967067e5f768140a5af3c8abebd1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "da68599b-ce0d-4137-aae9-9e3171d391e9", "node_type": "1", "metadata": {}, "hash": "d1645987e3b65656e5cfc0216234f4437592dfbc90c18713bacc8d326e2bd587", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[4] Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and J\u00f6rg Sander. Lof: identifying density-based local outliers. In Proceedings of the 2000 ACM SIGMOD international conference on Management of data, pages 93\u2013104, 2000.\n\n", "mimetype": "text/plain", "start_char_idx": 64882, "end_char_idx": 65109, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "da68599b-ce0d-4137-aae9-9e3171d391e9", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "358ae5d7-bde8-4561-aa2b-eba99ed39057", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "20b1fac50cd8af2903a4a017b80a43356b98919a2593d0fa7cd7872891c6cd9c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6d9d44b3-ae5c-4df0-bdf0-19037734bb71", "node_type": "1", "metadata": {}, "hash": "951535157129115255b70a2b2a6c9408657787c4a5a9f4609e681bee6d37abf6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[5] Sebastian Buschj\u00e4ger, Philipp-Jan Honysz, and Katharina Morik. Randomized outlier detection with trees. International Journal of Data Science and Analytics, pages 1-14, 2020.\n\n[6] Guilherme O Campos, Arthur Zimek, J\u00f6rg Sander, Ricardo JGB Campello, Barbora Micenkov\u00e1, Erich Schubert, Ira Assent, and Michael E Houle. On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study. Data mining and knowledge discovery, 30(4):891-927, 2016.\n\n", "mimetype": "text/plain", "start_char_idx": 65109, "end_char_idx": 65586, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "6d9d44b3-ae5c-4df0-bdf0-19037734bb71", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "da68599b-ce0d-4137-aae9-9e3171d391e9", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "5302d7a3c27dbd383daef97de8b25a24d25c3da1af5d6b86b2e983c2f314b3cf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "841f9695-2cd1-498f-8ad5-31c7302bbd86", "node_type": "1", "metadata": {}, "hash": "5bb17b9a7b23559d88ebc1b8a98b94a2d042b3731c39120d38d0f7ce3ef21c43", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[7] David Cortes. Imputing missing values with unsupervised random trees. arXiv preprint arXiv:1911.06646, 2019.\n\n", "mimetype": "text/plain", "start_char_idx": 65586, "end_char_idx": 65700, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "841f9695-2cd1-498f-8ad5-31c7302bbd86", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6d9d44b3-ae5c-4df0-bdf0-19037734bb71", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "2e0e1696232a20ab2be789cde79433017112ebbe9a19721c120793f8c86ee6f6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "39b1f13f-21e3-4448-9eda-82c9e2c547d2", "node_type": "1", "metadata": {}, "hash": "86de0fd70aeface6b8aef9d13e2d17d8d2db93afc4380307a9b0d4d56d283bcf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[8] Jesse Davis and Mark Goadrich. The relationship between precision-recall and roc curves. In Proceedings of the 23rd international conference on Machine learning, pages 233-240, 2006.\n\n", "mimetype": "text/plain", "start_char_idx": 65700, "end_char_idx": 65888, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "39b1f13f-21e3-4448-9eda-82c9e2c547d2", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "841f9695-2cd1-498f-8ad5-31c7302bbd86", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "d2c6ddf097b0790c451cd142941cc4f7d32489f91bdff2e9ae5aff0ab7d00ae4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "32f8b8f4-4312-4d87-a47a-968c4caefcd9", "node_type": "1", "metadata": {}, "hash": "a3e3e1fe74a3b8ebe645f6599a1de4bbd4a2c993c74f6704a3b460f62b94e5e9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[9] Nicolas Goix, Nicolas Drougard, Romain Brault, and Mael Chiapino. One class splitting criteria for random forests. In Asian Conference on Machine Learning, pages 343-358. ", "mimetype": "text/plain", "start_char_idx": 65888, "end_char_idx": 66063, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "32f8b8f4-4312-4d87-a47a-968c4caefcd9", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "39b1f13f-21e3-4448-9eda-82c9e2c547d2", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "3fd5107a6608a6db6fcbf5fa048855090c591da5392470f6a0d790f94a053d69", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "56655aa7-39fe-47f9-a842-f4d2bc3e9458", "node_type": "1", "metadata": {}, "hash": "09ffdd7c192afe4f070df0b0678aeb14952e9d15c8eede0949a9bf3156e21cf5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "PMLR, 2017.\n\n", "mimetype": "text/plain", "start_char_idx": 66063, "end_char_idx": 66076, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "56655aa7-39fe-47f9-a842-f4d2bc3e9458", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "32f8b8f4-4312-4d87-a47a-968c4caefcd9", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "28c03be75fef6342e7f2994823059332b88cc2ec502dd16c4b78dbe7ca844780", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "010a6d08-8885-407c-83a6-904f0ad59783", "node_type": "1", "metadata": {}, "hash": "a3e3e1fe74a3b8ebe645f6599a1de4bbd4a2c993c74f6704a3b460f62b94e5e9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[10] Nicolas Goix, Nicolas Drougard, Romain Brault, and Mael Chiapino. One class splitting criteria for random forests. In Asian Conference on Machine Learning, pages 343-358. ", "mimetype": "text/plain", "start_char_idx": 66076, "end_char_idx": 66252, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "010a6d08-8885-407c-83a6-904f0ad59783", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "56655aa7-39fe-47f9-a842-f4d2bc3e9458", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "f472f8a162d2ebb1263b79e9e6d6f7478861bd3c428e489f50ae10fd287345cf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "62e55f17-1bcf-48de-8445-fd400f5f5821", "node_type": "1", "metadata": {}, "hash": "fe9f177c43ef316e18eb3b72accbb880c6ab7b61b944504da1cd1ddd3487ffeb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "PMLR, 2017.\n\n", "mimetype": "text/plain", "start_char_idx": 66252, "end_char_idx": 66265, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "62e55f17-1bcf-48de-8445-fd400f5f5821", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "010a6d08-8885-407c-83a6-904f0ad59783", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "28c03be75fef6342e7f2994823059332b88cc2ec502dd16c4b78dbe7ca844780", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d2ba5be-e05c-4592-aca1-6ef0fe71de45", "node_type": "1", "metadata": {}, "hash": "2191d1b6354e60ba71ad4915e5d8841e9600ed5555ca1fa3e3973bb813076540", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[11] Sudipto Guha, Nina Mishra, Gourav Roy, and Okke Schrijvers. Robust random cut forest based anomaly detection on streams. In International conference on machine learning, pages 2712\u20132721. ", "mimetype": "text/plain", "start_char_idx": 66265, "end_char_idx": 66457, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4d2ba5be-e05c-4592-aca1-6ef0fe71de45", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "62e55f17-1bcf-48de-8445-fd400f5f5821", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "73bedcc6eec4f08e723d6e1a87798edf1bc7ff8d5c79dd7d0b96538958e6d1f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d9356788-5acb-43a2-a937-36d1e846590b", "node_type": "1", "metadata": {}, "hash": "d6861ca32a469d053b20e3e9154b16ae958bd89b383cb35531bcc0de1ccdaa72", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "PMLR, 2016.\n\n", "mimetype": "text/plain", "start_char_idx": 66457, "end_char_idx": 66470, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "d9356788-5acb-43a2-a937-36d1e846590b", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d2ba5be-e05c-4592-aca1-6ef0fe71de45", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "f34bff1ab3f3e7604f83268a5c9e3dc0bf8e1285bdfa39af06174decba620dd3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dcd61a94-dd8a-4cec-a40e-57108e2f5e50", "node_type": "1", "metadata": {}, "hash": "01fe9acef58fabb990d5fdf5c27e9bf6bf5030369ef697f90288debfe2196b00", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[12] Sahand Hariri, Matias Carrasco Kind, and Robert J Brunner. Extended isolation forest. arXiv preprint arXiv:1811.02141, 2018.\n\n", "mimetype": "text/plain", "start_char_idx": 66470, "end_char_idx": 66601, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "dcd61a94-dd8a-4cec-a40e-57108e2f5e50", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d9356788-5acb-43a2-a937-36d1e846590b", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "648a505091122ed13257647f18203bd3b18614165f9d71d3a0fd8d55e8cfb20b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "14305d43-5a48-4d69-83b6-83f01afe2dca", "node_type": "1", "metadata": {}, "hash": "30b6b87ac5718d33c481c48e1ba4b4abbff2e49253f663d31859cc3296c90cf7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[13] Hans-Peter Kriegel, Peer Kroger, Erich Schubert, and Arthur Zimek. Interpreting and unifying outlier scores. In Proceedings of the 2011 SIAM International Conference on Data Mining, pages 13\u201324. ", "mimetype": "text/plain", "start_char_idx": 66601, "end_char_idx": 66801, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "14305d43-5a48-4d69-83b6-83f01afe2dca", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dcd61a94-dd8a-4cec-a40e-57108e2f5e50", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "806c32412d63a11966eb1c6c2a90fde93a95b3d1f554cd992d4591f5123a30e4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9d5ba887-23c4-4c92-9697-ee3a72cb98b9", "node_type": "1", "metadata": {}, "hash": "4497ade4d72664cdde21738ed9a989601023ef1fa3e75ab2941445cd138e8917", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SIAM, 2011.\n\n", "mimetype": "text/plain", "start_char_idx": 66801, "end_char_idx": 66814, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "9d5ba887-23c4-4c92-9697-ee3a72cb98b9", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "14305d43-5a48-4d69-83b6-83f01afe2dca", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "6d515cf97c907bad96817a0c59c6a80757bc51e5ea40cbc9f9e37705021482ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad736fb5-0a7c-4903-aaef-045adc9773f6", "node_type": "1", "metadata": {}, "hash": "ded313cd3d964390c81526064903bce15bc6077a799b3279b92b2c3906e6e6fa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[14] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation forest. In 2008 Eighth IEEE International Conference on Data Mining, pages 413-422. ", "mimetype": "text/plain", "start_char_idx": 66814, "end_char_idx": 66960, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "ad736fb5-0a7c-4903-aaef-045adc9773f6", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9d5ba887-23c4-4c92-9697-ee3a72cb98b9", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "7bc251ab7c904a975fc0ef9f43288ba0c349add06d9dd9a4f4e655ac266cbcc0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4335492c-75ca-4dbe-a95d-95fd609afb0d", "node_type": "1", "metadata": {}, "hash": "f5804c75a7f59a794e778cf3ec3227b3b9b345822c884de44622a4559d56dcdd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "IEEE, 2008.\n\n", "mimetype": "text/plain", "start_char_idx": 66960, "end_char_idx": 66973, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4335492c-75ca-4dbe-a95d-95fd609afb0d", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad736fb5-0a7c-4903-aaef-045adc9773f6", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "8850254895876235fd8780bdc45012620bcc371f2eab9465a1c6e4067ff1fbb1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "466bec1c-f0c5-489a-b98d-b76ad3576852", "node_type": "1", "metadata": {}, "hash": "ce915597d1864e6117b9701b67510f485c258671cdea5e1314efec80493ee150", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[15] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. On detecting clustered anomalies using sciforest. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 274-290. ", "mimetype": "text/plain", "start_char_idx": 66973, "end_char_idx": 67177, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "466bec1c-f0c5-489a-b98d-b76ad3576852", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4335492c-75ca-4dbe-a95d-95fd609afb0d", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "39fd3ff326db9cdd8a1d22b2a96bbbc9f0193c0273deed68a429823f8b382fc5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8522ccc7-dcc7-4234-8f7f-c6471e5c50b9", "node_type": "1", "metadata": {}, "hash": "327e55c7b5e433cb4460f32171ecf79160a78105aee9695b34992ce99eb754d0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Springer, 2010.\n\n", "mimetype": "text/plain", "start_char_idx": 67177, "end_char_idx": 67194, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "8522ccc7-dcc7-4234-8f7f-c6471e5c50b9", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "466bec1c-f0c5-489a-b98d-b76ad3576852", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "d705267eb27bc374849c06721deb25b79e8ac8b028275ca94479b026140cccff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ff08227-72d6-4b37-9c5c-7ae0fef417f1", "node_type": "1", "metadata": {}, "hash": "9d8d39bcd8c3b8c1517cadf4e928f0ac683890923808e11c3766e74f9485c17d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[16] J Ross Quinlan. ", "mimetype": "text/plain", "start_char_idx": 67194, "end_char_idx": 67215, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "0ff08227-72d6-4b37-9c5c-7ae0fef417f1", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8522ccc7-dcc7-4234-8f7f-c6471e5c50b9", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "fdb35d95516cb7636fc19c7cacb2b5e7e1ea59419db0430e22f72e80265e7dea", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4adadcd3-02e3-4353-9d26-38b4fa5e0758", "node_type": "1", "metadata": {}, "hash": "2e17aed9ae3e53c341545fedaaee4fd790628e54d482e8dba0ecc467adf2f2c2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "C4. 5: programs for machine learning. Elsevier, 2014.\n\n", "mimetype": "text/plain", "start_char_idx": 67215, "end_char_idx": 67270, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, {"id_": "4adadcd3-02e3-4353-9d26-38b4fa5e0758", "embedding": null, "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d7728bd-6799-46bf-9ae1-f85a1705b66e", "node_type": "4", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "44f69844255901cb18ca7eaf5964bbb2d6cda1a8720d0d00f656c3406f74c87d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ff08227-72d6-4b37-9c5c-7ae0fef417f1", "node_type": "1", "metadata": {"title": "Revisiting randomized choices in isolation forests", "authors": "Cortes et al.", "year": 2021, "file_path": "ad-papers-pdf/randomised_choices_in_isolation_forest.pdf"}, "hash": "65f6937d152e5edee83be0d78ae5588866ed0592604bd203ce465de957b610fb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[17] Parikshit Ram and Alexander G Gray. Density estimation trees. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 627-635, 2011.\n\n[18] Shebuti Rayana. Odds library. http://odds.cs.stonybrook.edu, 2016.\n\n[19] Bernhard Sch\u00f6lkopf, John C Platt, John Shawe-Taylor, Alex J Smola, and Robert C Williamson. Estimating the support of a high-dimensional distribution. Neural computation, 13(7):1443\u20131471, 2001.", "mimetype": "text/plain", "start_char_idx": 67270, "end_char_idx": 67733, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}]